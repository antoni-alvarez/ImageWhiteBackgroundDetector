{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad438f-7200-41b9-8d6a-114ab3ea333d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import layers\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b8c94f-bdaa-4eba-a837-b1ba724fb9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed = 122 # Must be same for train and validation\n",
    "validation_split = 0.3\n",
    "data_path = '../images'\n",
    "\n",
    "ds_train = tf.keras.utils.image_dataset_from_directory(\n",
    "directory = data_path,\n",
    "batch_size = BATCH_SIZE,\n",
    "validation_split = validation_split,\n",
    "subset = 'training',\n",
    "seed = random_seed)\n",
    "\n",
    "ds_test = tf.keras.utils.image_dataset_from_directory(\n",
    "directory = data_path,\n",
    "batch_size = BATCH_SIZE,\n",
    "validation_split = validation_split,\n",
    "subset = 'validation',\n",
    "seed = random_seed)\n",
    "\n",
    "ds_train = ds_train.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9ec6f1-5296-4eee-91e5-3453bedf4440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iterator = iter(ds_train)\n",
    "images, labels = next(iterator)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(images[i].numpy().astype(int))\n",
    "    plt.title('1 - Valid' if labels[i] == 1 else '0 - Invalid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d26cb4-c04e-4740-8322-bdfeb73eb47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    data_preprocessing = keras.Sequential([\n",
    "        keras_cv.layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "        keras_cv.layers.Grayscale(output_channels=1),\n",
    "        layers.Rescaling(1./255, input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    ])\n",
    "\n",
    "    data_augmentation = keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal_and_vertical\", input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        layers.RandomZoom(0.1),\n",
    "    ])\n",
    "\n",
    "    batch_normalization = keras.Sequential([\n",
    "        keras.layers.BatchNormalization(),\n",
    "    ])\n",
    "    \n",
    "    model.add(data_preprocessing)\n",
    "    model.add(data_augmentation)\n",
    "    model.add(batch_normalization)\n",
    "    \n",
    "    model.add(layers.Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "     \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[keras.metrics.BinaryAccuracy()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c586bae1-cd67-498c-b7ff-be72d6aecad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "\n",
    "epochs = 30;\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath='best_model.keras', save_best_only=True, save_weights_only=False, monitor='val_binary_accuracy', mode='max', verbose=1)\n",
    "\n",
    "history = model.fit(ds_train, epochs=epochs, validation_data=ds_test, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd304f9-3ffa-457c-a8fb-50512879dfa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = models.load_model('best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43630242-da55-458b-800e-6621a038edbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = best_model.evaluate(ds_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f30e821-d80a-42a4-a968-6e2a479087ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy Plot')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ac26e-f9ed-4b49-8bcb-3c4f66a41678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_names = ['Invalid', 'Valid']\n",
    "\n",
    "predictions = best_model.predict(ds_test)\n",
    "pred_labels = np.where(predictions > 0.5, 1, 0)\n",
    "\n",
    "real_labels = np.concatenate([labels.numpy() for _, labels in ds_test])\n",
    "\n",
    "cm = tf.math.confusion_matrix(labels=real_labels, predictions=pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec451e-191d-4947-adbb-c1884ac2efb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "false_positives = np.unique(np.where((pred_labels.flatten() == 1) & (real_labels == 0))[0])\n",
    "false_negatives = np.unique(np.where((pred_labels.flatten() == 0) & (real_labels == 1))[0])\n",
    "\n",
    "print(false_positives)\n",
    "print(false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f1b80-51ad-462c-a863-5b4a055e2fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "false_positives = np.unique(np.where((pred_labels.flatten() == 1) & (real_labels == 0))[0])\n",
    "false_negatives = np.unique(np.where((pred_labels.flatten() == 0) & (real_labels == 1))[0])\n",
    "\n",
    "# Imprimir las imágenes de falsos positivos\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.suptitle(\"Falsos Positivos\")\n",
    "for i, idx in enumerate(false_positives[:25]):\n",
    "    image, label = ds_test.unbatch().skip(idx).take(1).as_numpy_iterator().next()\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image.astype(int))\n",
    "    plt.title(f'{label} - {target_names[label]}')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Imprimir las imágenes de falsos negativos\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.suptitle(\"Falsos Negativos\")\n",
    "for i, idx in enumerate(false_negatives[:25]):\n",
    "    image, label = ds_test.unbatch().skip(idx).take(1).as_numpy_iterator().next()\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image.astype(int))\n",
    "    plt.title(f'{label} - {target_names[label]}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034cc74-4e95-4380-bff4-adfacb37f7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, cmap=plt.cm.Greens)\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.colorbar()\n",
    "\n",
    "classes = ['Invalid', 'Valid']\n",
    "plt.xticks(range(len(classes)), classes)\n",
    "plt.yticks(range(len(classes)), classes)\n",
    "\n",
    "text_labels = ['TN', 'FP', 'FN', 'TP']\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        plt.text(j, i, f\"{text_labels[i*len(classes)+j]}: {cm[i, j]}\", ha='center', va='center', fontsize=12)\n",
    "\n",
    "plt.ylabel('Real Label', fontsize=14)\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb73f4-662f-4808-ac70-f30c1011c268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_image = \"https://media.adeo.com/marketplace/LMES/83431706/1834868.jpeg\"\n",
    "test_image_path = tf.keras.utils.get_file('Test Image 8', origin=test_image)\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    test_image_path, target_size=(IMG_SIZE, IMG_SIZE)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0)\n",
    "\n",
    "predictions = best_model.predict(img_array)\n",
    "predicted_class = 1 if predictions[0][0] > 0.5 else 0\n",
    "confidence = 100 * np.abs(predictions[0][0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {}. Confidence {:.2f}\"\n",
    "    .format(classes[predicted_class], confidence)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
